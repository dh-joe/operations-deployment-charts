inference_services:
  nllb-200-gpu:
    predictor:
      image: "machinelearning-liftwing-inference-services-llm"
      image_version: "2024-03-21-072005-publish"
      custom_env:
        - name: MODEL_NAME
          value: "nllb-200"
        - name: LLM_CLASS
          value: "llm.NLLB"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/llm/nllb-200-distilled-600M/"
      container:
        resources:
          limits:
            cpu: "4"
            memory: 6Gi
            amd.com/gpu: 1
          requests:
            cpu: "4"
            memory: 6Gi
            amd.com/gpu: 1
