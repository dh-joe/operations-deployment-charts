docker:
  registry: docker-registry.discovery.wmnet/wikimedia
  imagePullPolicy: IfNotPresent

networkpolicy:
  egress:
    enabled: true
    # These endpoints should be reachable by Istio proxy sidecars.
    dst_nets:
      - cidr: 10.2.1.54/32 # thanos-swift.svc.codfw.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.2.54/32 # thanos-swift.svc.eqiad.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.1.22/32 # api-ro.svc.codfw.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.2.22/32 # api-ro.svc.eqiad.wmnet
        ports:
        - port: 443
          protocol: tcp
      - cidr: 10.2.1.45/32 # eventgate-main.svc.codfw.wmnet
        ports:
        - port: 4492
          protocol: tcp
      - cidr: 10.2.2.45/32 # eventgate-main.svc.eqiad.wmnet
        ports:
        - port: 4492
          protocol: tcp

monitoring:
  enabled: true

inference:
  annotations:
    sidecar.istio.io/inject: "true"

inference_services:
  bloom-560m:
    predictor:
      image: "machinelearning-liftwing-inference-services-bloom"
      image_version: "2023-06-08-144706-publish"
      custom_env:
        - name: MODEL_NAME
          value: "bloom-560m"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/bloom/bloom-560m/20230512141345/"
      resources:
        limits:
          cpu: "4"
          memory: 6Gi
        requests:
          cpu: "4"
          memory: 6Gi
  bloom-560m-gpu:
    predictor:
      image: "machinelearning-liftwing-inference-services-bloom"
      image_version: "2023-06-08-144706-publish"
      custom_env:
        - name: MODEL_NAME
          value: "bloom-560m"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/bloom/bloom-560m/20230512141345/"
      resources:
        limits:
          cpu: "4"
          memory: 6Gi
          amd.com/gpu: 1
        requests:
          cpu: "4"
          memory: 6Gi
          amd.com/gpu: 1
  bloom-3b:
    predictor:
      image: "machinelearning-liftwing-inference-services-bloom"
      image_version: "2023-05-19-145022-publish"
      custom_env:
        - name: MODEL_NAME
          value: "bloom-3b"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/bloom/bloom-3b/"
      resources:
        limits:
          cpu: "8"
          memory: 20Gi
        requests:
          cpu: "8"
          memory: 20Gi
