inference_services:
  revertrisk-wikidata:
    predictor:
      image: "machinelearning-liftwing-inference-services-revertrisk-wikidata"
      image_version: "2024-06-03-133433-publish"
      custom_env:
        - name: MODEL_NAME
          value: "revertrisk-wikidata"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/experimental/revertrisk-wikidata/20230512162400/"
        - name: WIKI_URL
          value: "http://mw-api-int-ro.discovery.wmnet:4680"
      container:
        resources:
          limits:
            cpu: "2"
            memory: 4Gi
          requests:
            cpu: "2"
            memory: 4Gi
  logo-detection:
    predictor:
      image: "machinelearning-liftwing-inference-services-logo-detection"
      image_version: "2024-05-16-145409-publish"
      custom_env:
        - name: MODEL_NAME
          value: "logo-detection"
        - name: STORAGE_URI
          value: "s3://wmf-ml-models/logo-detection/20240417132942/"
      container:
        resources:
          limits:
            cpu: "2"
            memory: 2Gi
          requests:
            cpu: "2"
            memory: 2Gi

  llama3:
      predictor:
        image: "machinelearning-liftwing-inference-services-huggingface"
        image_version: "2024-06-14-101426-publish"
        custom_env:
          - name: MODEL_NAME
            value: "llama3"
          - name: STORAGE_URI
            value: "s3://wmf-ml-models/llm/llama3-8B-instruct/"
        container:
          command: [ "python3", "-m", "huggingfaceserver", "--model_dir", "/mnt/models", "--model_name", "llama3", "--backend", "huggingface" ]
          resources:
            limits:
              cpu: "8"
              memory: 35Gi
              amd.com/gpu: "1"
            requests:
              cpu: "8"
              memory: 35Gi
              amd.com/gpu: "1"

  bert:
      predictor:
        image: "machinelearning-liftwing-inference-services-huggingface"
        image_version: "2024-05-23-145141-publish"
        custom_env:
          - name: MODEL_NAME
            value: "bert"
          - name: STORAGE_URI
            value: "s3://wmf-ml-models/llm/bert-base-uncased/"
        container:
          command: [ "python3", "-m", "huggingfaceserver", "--model_dir", "/mnt/models", "--model_name", "bert"]
          resources:
            limits:
              memory: 2Gi
            requests:
              memory: 2Gi

  articlequality:
    predictor:
      image: "machinelearning-liftwing-inference-services-articlequality"
      image_version: "2024-06-14-140832-publish"
      custom_env:
        - name: MODEL_NAME
          value: "articlequality"
      resources:
        limits:
          memory: 1Gi
        requests:
          memory: 1Gi



external_services_app_label_selector: app-wmf
external_services:
  cassandra:
  - ml-cache-a-eqiad
  - ml-cache-a-codfw
