# DSE k8s cluster specific configuratrion.
# In DSE (development), use Kafka jumbo-eqiad cluster.
# When we move to wikikube, we will use Kafka main clusters.

app:
  config_files:
    app.config.yaml:

      # Configs for eventutilities python stream_manager.
      stream_manager:
        # Configure sources and sinks.
        source:
          options:
            bootstrap_servers: kafka-jumbo1001.eqiad.wmnet:9093,kafka-jumbo1002.eqiad.wmnet:9093,kafka-jumbo1003.eqiad.wmnet:9093,kafka-jumbo1004.eqiad.wmnet:9093,kafka-jumbo1005.eqiad.wmnet:9093,kafka-jumbo1006.eqiad.wmnet:9093,kafka-jumbo1007.eqiad.wmnet:9093,kafka-jumbo1008.eqiad.wmnet:9093,kafka-jumbo1009.eqiad.wmnet:9093
            consumer_group: mw_page_content_change_enrich__dse-k8s-eqiad_000

        sink:
          options:
            bootstrap_servers: kafka-jumbo1001.eqiad.wmnet:9093,kafka-jumbo1002.eqiad.wmnet:9093,kafka-jumbo1003.eqiad.wmnet:9093,kafka-jumbo1004.eqiad.wmnet:9093,kafka-jumbo1005.eqiad.wmnet:9093,kafka-jumbo1006.eqiad.wmnet:9093,kafka-jumbo1007.eqiad.wmnet:9093,kafka-jumbo1008.eqiad.wmnet:9093,kafka-jumbo1009.eqiad.wmnet:9093
            # Override this in values.codfw.yaml
            kafka_topic_prefix: eqiad.

  flinkConfiguration:
    "high-availability.storageDir": s3://mediawiki-page-content-change-enrichment-eqiad/dse-k8s-eqiad/high_availability
    "state.checkpoints.dir": s3://mediawiki-page-content-change-enrichment-eqiad/dse-k8s-eqiad/checkpoints # needed for upgradeMode: savepoint
    "state.savepoints.dir": s3://mediawiki-page-content-change-enrichment-eqiad/dse-k8s-eqiad/savepoints # needed for upgradeMode: savepoint

  taskManager:
    # NOTE: taskManager.replicas takes precedence over job.parellism.
    # For now, set replicas to 2, as the input mediawiki.page_change stream has only 2
    # Kafka topic-partitions (eqiad and codfw).  We'll need to adjust
    # this accordingly when?
    # - we deploy to wikikube and figure out what
    #   our multi-DC stream processing layout will be.
    # - if/when we we increase the number of Kafka partitions per topic.
    # NOTE: When we deploy to wikikube, we can run with a single replica
    # in each DC, as we will be deployingin active/active single
    # compute mode, and each deployment will consume only a single topic.
    replicas: 2
    resource:
      cpu: 2
      # When backfilling, a single TM maxed out at around 2.7GB.
      # Reserve 3G.
      memory: 3000m

kafka:
  allowed_clusters: [jumbo-eqiad]

networkpolicy:
  egress:
    dst_nets:

      # thanos-swift cluster in eqiad for checkpoints
      - cidr: 10.2.2.54/32   # thanos-swift.svc.eqiad.wmnet
        ports:
          - port: 443
            protocol: tcp
