app:
  image: docker-registry.discovery.wmnet/repos/data-engineering/mediawiki-event-enrichment
  version: v1.0.2

  job:
    # TODO: add job args, like kafka brokers and stream names, once supported.
    pythonEntryPoint: /srv/app/pipeline.py
    # job.parallelism controls the number of TaskManagers (if taskManager.replicas is not set).
    # For now, set this to 2, as the input mediawiki.page_change stream has only 2
    # Kafka topic-partitions (eqiad and codfw).  We'll need to adjust
    # this accordingly when?
    # - we deploy to wikikube and figure out what
    #   our multi-DC stream processing layout will be.
    # - if/when we we increase the number of Kafka partitions per topic.
    parallelism: 2
    # TODO: figure out what upgradeMode should be.
    upgradeMode: stateless

  jobManager:
    resource:
      memory: 1600m

  taskManager:
    resource:
      memory: 1600m

