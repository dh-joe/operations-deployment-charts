docker:
  registry: docker-registry.discovery.wmnet

app:
  version: &base-image-version 2024-11-20-130943-4ca02ad5b46df5377ad1535657c302a6ea919340@sha256:61c8740217be4a4e13c3d85deca9b9659e4128ac3399f3cf912e07e9c1f2ad75
  executor_pod_image_version: *base-image-version

service:
  deployment: production

config:
  airflow:
    dbHost: 'an-db1001.eqiad.wmnet'
    config:
      datahub:
        cluster: prod
        conn_id: datahub_gms_prod
        enabled: true
  connections:
    s3_dpe:
      extra:
        endpoint_url: https://rgw.eqiad.dpe.anycast.wmnet
        region_name: dpe
    datahub_gms_prod:
      conn_type: datahub-rest
      host: http://datahub-gms-production.datahub.svc:8080
  oidc:
    idp_server: idp.wikimedia.org

external_services:
  gitsync:
    # git-sync pulls code from our gitlab instance
    gitlab: [wikimedia]
  scheduler:
    # the scheduler needs to be able to send alert emails
    wikimail: [mx]
    # it also needs to be able to move task logs to s3 once they complete
    s3: [eqiad-dpe]
  kerberos:
    # the airflow kerberos compomnent needs to be able to talk to our KDC
    # to get an initial TGT, as well as renew it
    kerberos: [kdc]
  webserver:
    # The webserver needs to talk to CAS to perform the OAuth dance, to log
    # users in
    cas: [idp]
    # The webserver needs to talk to S3 to fetch task logs for completed tasks
    s3: [eqiad-dpe]
  task-pod:
    # Task pods need access to kerberos to get a Client-to-Service ticket from
    # their TGT, by talking to the TGS
    kerberos: [kdc]
    # Some tasks connect to S3 directly
    s3: [eqiad-dpe]

gitsync:
  image_tag: 2024-08-22-120818-fbafbcdb385bf1008ba0ac8ee350e9fe411a057d@sha256:3e01121704b405a08649012571aba0ce6834ab3aa3428df0b02a476b7ba4c3f5
  volume:
    storage_class: ceph-cephfs-ssd

kerberos:
  volume:
    storage_class: ceph-cephfs-ssd

worker:
  config:
    hadoop:
      hdfs:
        dfs.cluster.administrators: hdfs analytics-admins,ops
        dfs.hosts.exclude: /etc/hadoop/conf.analytics-hadoop/hosts.exclude
      core:
        ha.zookeeper.quorum: an-conf1001.eqiad.wmnet,an-conf1002.eqiad.wmnet,an-conf1003.eqiad.wmnet
      yarn:
        yarn.resourcemanager.keytab: /etc/security/keytabs/hadoop/yarn.keytab
        yarn.resourcemanager.zk-address: an-conf1001.eqiad.wmnet,an-conf1002.eqiad.wmnet,an-conf1003.eqiad.wmnet
    spark:
      spark:
        spark.executorEnv.REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
        spark.yarn.appMasterEnv.REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
        spark.yarn.historyServer.address: yarn.wikimedia.org
      hive:
        hive.metastore.kerberos.keytab.file: /etc/security/keytabs/hive/hive.keytab
        hive.server2.authentication.kerberos.keytab: /etc/security/keytabs/hive/hive.keytab
