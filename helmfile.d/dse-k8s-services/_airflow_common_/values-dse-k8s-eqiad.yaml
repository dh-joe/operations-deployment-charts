docker:
  registry: docker-registry.discovery.wmnet

app:
  version: &base-image-version 2024-11-08-105102-25463ca689380e11d0f3986eee498ad3bc7b0870@sha256:9937aa8f41e23c996729d7218da9811362b70fb135af5bbea11ea6327b1d3db2
  executor_pod_image_version: *base-image-version

service:
  deployment: production

config:
  airflow:
    dbHost: 'an-db1001.eqiad.wmnet'
    config:
      datahub:
        cluster: prod
        conn_id: datahub_gms_prod
        enabled: true
  connections:
    s3_dpe:
      extra:
        endpoint_url: https://rgw.eqiad.dpe.anycast.wmnet
        region_name: dpe
    datahub_gms_prod:
      conn_type: datahub-rest
      host: http://datahub-gms-production.datahub.svc:8080
  oidc:
    idp_server: idp.wikimedia.org

external_services:
  gitlab: [wikimedia]
  wikimail: [mx]
  kerberos: [kdc]
  cas: [idp]
  s3: [eqiad-dpe]

gitsync:
  image_tag: 2024-08-22-120818-fbafbcdb385bf1008ba0ac8ee350e9fe411a057d@sha256:3e01121704b405a08649012571aba0ce6834ab3aa3428df0b02a476b7ba4c3f5
  volume:
    storage_class: ceph-cephfs-ssd

kerberos:
  volume:
    storage_class: ceph-cephfs-ssd

worker:
  config:
    hadoop:
      hdfs:
        dfs.cluster.administrators: hdfs analytics-admins,ops
        dfs.hosts.exclude: /etc/hadoop/conf.analytics-hadoop/hosts.exclude
      core:
        ha.zookeeper.quorum: an-conf1001.eqiad.wmnet,an-conf1002.eqiad.wmnet,an-conf1003.eqiad.wmnet
      yarn:
        yarn.resourcemanager.keytab: /etc/security/keytabs/hadoop/yarn.keytab
        yarn.resourcemanager.zk-address: an-conf1001.eqiad.wmnet,an-conf1002.eqiad.wmnet,an-conf1003.eqiad.wmnet
    spark:
      spark:
        spark.executorEnv.REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
        spark.yarn.appMasterEnv.REQUESTS_CA_BUNDLE: /etc/ssl/certs/ca-certificates.crt
        spark.yarn.historyServer.address: yarn.wikimedia.org
      hive:
        hive.metastore.kerberos.keytab.file: /etc/security/keytabs/hive/hive.keytab
        hive.server2.authentication.kerberos.keytab: /etc/security/keytabs/hive/hive.keytab
