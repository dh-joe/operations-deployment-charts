docker:
  pull_policy: IfNotPresent
  registry: docker-registry.discovery.wmnet

net_istio:
  controller:
    replicaCount: 2
    resources:
      requests:
        cpu: 200m
        memory: 40Mi
      limits:
        cpu: 1000m
        memory: 400Mi
  webhook:
    replicaCount: 2
core:
  activator:
    replicaCount: 2
    resources:
      requests:
        cpu: 1000m
        memory: 800Mi
      limits:
        cpu: 3000m
        memory: 800Mi
  autoscaler:
    replicaCount: 2
    resources:
      requests:
        cpu: 1000m
        memory: 100Mi
      limits:
        cpu: 3000m
        memory: 600Mi
  controller:
    replicaCount: 2
    resources:
      requests:
        cpu: 500m
        memory: 100Mi
      limits:
        cpu: 2500m
        memory: 1000Mi
  webhook:
    replicaCount: 2

  config_autoscaler:
    scale-down-delay: "15m"
    # The Activator pods can be placed between Ingress and Target pods (like
    # Kserve ones) to buffer traffic in case a surge of requests happens.
    # It turns out that figuring out the exact sweet spot is not easy, plus
    # it adds more complexity to the request path.
    # Setting this value to zero forces the Activator pods to be placed in
    # the request path only for scale-to-zero environments (where revisions
    # can have zero serving pods, waiting for requests to happen).
    # More info https://knative.dev/docs/serving/load-balancing/target-burst-capacity/
    target-burst-capacity: "0"
    # Percentage of avg concurrent (if configured as metric, otherwise rps etc..)
    # requests to initiate a scale up action. Basically knative tries to scale
    # up earlier to smooth the transition time to more capacity (to avoid overloading
    # the other instances). Default is 70.
    # More info: https://knative.dev/docs/serving/autoscaling/concurrency/#target-utilization
    container-concurrency-target-percentage: "85"
