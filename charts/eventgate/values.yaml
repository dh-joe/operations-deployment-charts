# Default values for EventGate.

helm_scaffold_version: 0.1 # This can be useful when backporting fixes.
docker:
  registry: docker-registry.wikimedia.org
  pull_policy: IfNotPresent
resources:
  replicas: 1


service:
  # valid values are "production" and "minikube" and "none".
  # If "none", no k8s Service will be deployed for this release.
  deployment: minikube
  # You need to define this if "production" is used. In minikube environments let it autoallocate
  port: null
  # Set routing_tag to the same (arbitrary) value for all releases that you want
  # this k8s Service to route to.
  # If you don't to deploy a service with a specific release (e.g. a canary), set service: false
  # routing_tag defaults to .Release.Name, so by default a Service will only route to the release it is part of.
  # routing_tag:

tls:
  enabled: false
  image_version: latest
  public_port: 4192 # the port where TLS will be exposed
  # To be defined in a private space
  certs:
    cert: "snakeoil"
    key: "snakeoil"
  telemetry:
    enabled: false
    port: 9361


monitoring:
  enabled: true
  image_version: latest

# To be defined in a private space
# certs:
#   cert: ... # The service public certificate
#   key: ...  # The service private key

# Debug mode adds the --profile and --inspect flags to the NodeJS service, and
# also deploys a wmfdebug sidecar container in the pod. You can get the v8.log profiling output
# from the pod with e.g (staging):
#   sudo KUBECONFIG=/etc/kubernetes/admin-staging.config kubectl cp -n eventgate-analytics -c eventgate-analytics-staging <pod_id>:/tmp/eventgate-analytics-v8.log ./
# You can connect to the Node Inspector on port 31229 for the master service-runner process,
# and port 31230 for the worker process.  Note that if a worker is restarted, it willl
# claim a new port and not be reachable externally.
# You can log into the wmfdebug container with e.g. (staging):
#   sudo KUBECONFIG=/etc/kubernetes/admin-staging.config kubectl exec -ti <pod_id> -n eventgate-analytics -c staging-wmfdebug bash
#
#debug_mode_enabled: false

subcharts:
  # Set this to true during local minikube development to get a Kafka pod deployed.
  # You only need to do this if you don't manually install the kafka-dev chart.
  kafka: false

main_app:
  # This should uniquely identify your chart's main app's name.
  # In the case where a chart is used for multiple deployments, this
  # should be set to something unique for each one.
  name: eventgate
  # Don't use docker.registry value for main_app image so we can override
  # and use locally built and cached images via --set main_app.image during development.
  image: docker-registry.wikimedia.org/wikimedia/eventgate-wikimedia
  version: latest # we use latest  in the defaults.
  port: 8192

  # See: https://phabricator.wikimedia.org/T220661#5117972
  requests:
    cpu: 200m
    memory: 150Mi
  limits:
    cpu: 2000m
    memory: 300Mi

  # The schema at this URL MUST have an JSONSchema examples event entry
  # That this eventgate instance is configured to allow.
  # This example event will be POSTed by the readinessProbe to determine
  # that eventgate is ready to handle events.
  readiness_probe_schema_url: 'file:///srv/service/schemas/event/primary/jsonschema/test/event/0.0.3'

  # EventGate service-runner app defaults config.
  # In production, these should be overridden in service/release specific values files.
  conf:
    # Events can be large; increase max body size
    # Note that this is larger than Kafka's message.max.bytes (set below).
    # The request body is accepted as an array of events, each of which
    # will be an individual message in Kafka.  Each individual
    # message must be smaller than message.max.bytes, but EventGate
    # can accept multiple events at once in the request body.
    max_body_size: 10mb

    # Mapping of stream names to allowed schemas
    stream_config_uri: /etc/eventgate/stream-config.yaml

    # This field in each event will be used to extract a
    # (possibly relative) schema uri.  The default is $schema.
    # An array of field names will cause EventGate to search for
    # fields by these names in each event, using the first match.
    schema_uri_field: $schema

    # If set, this URI will be prepended to any relative schema URI
    # extracted from each event's schema_field.

    # /srv/service/schemas/primary is in the eventgate image cloned at build
    # time from https://gerrit.wikimedia.org/r/schemas/event/primary.
    schema_base_uris:
      - 'file:///srv/service/schemas/event/primary/jsonschema/'

    # These schema URIs will be 'precached' on service startup.
    # They should be resolveable by the URI prefixes in schema_base_uris.
    # These should be set to the most comprehensive list for each release.
    schema_precache_uris:
      - /error/0.0.3
      - /test/event/0.0.3

    # This field in each event will be used to extract a destination 'stream' name.
    # This will equal the destination Kafka topic, unless a topic prefix
    # is also configured.
    stream_field: meta.stream

    # Prefix topics with the topic_prefix name and a .
    topic_prefix: datacenter1.

    # This field will be used in log messages to uniquely ID each event.
    id_field: meta.id

    # This field will be used to extract and set a Kafka message timestamp.
    dt_field: meta.dt

    # NOTE: This config is templated in config.yaml.
    #error_stream: eventgate-dev.error.validation

    # kafka configs go here.
    kafka:
      conf:
        # Override this in release specific values.yaml files
        metadata.broker.list: ['kafka.default.svc.cluster.local:31092']
        compression.codec: snappy
        # Match this to what is set on brokers in production.
        message.max.bytes: 4194304
        # Silence noisy connection reaper logging
        # https://github.com/Blizzard/node-rdkafka/issues/326
        # https://github.com/edenhill/librdkafka/issues/768#issuecomment-246302856
        log.connection.close: false
        # Force rdkafka to prefer IPv4 addresses for repeatablity.
        # See also: https://phabricator.wikimedia.org/T218268#5049090
        broker.address.family: v4
        # Emit rdkafka stats every 30 seconds
        # (Prometheus will only scrape statsd-exporterd every 60 seconds).
        statistics.interval.ms: 30000
        # Set these to enable Kafka producer TLS (no authentication, just encryption).
        #security.protocol: ssl
        # These ssl setttings are only used if security.protocol == ssl
        ssl.ca.location: /etc/eventgate/puppetca.crt.pem
        ssl.cipher.suites: ECDHE-ECDSA-AES256-GCM-SHA384
        ssl.curves.list: P-256
        ssl.sigalgs.list: ECDSA+SHA256

        # Uncomment to enable rdkafka trace logging (and set log_level: trace above)
        #event_cb: true
        #log_level: 7
        #debug: broker,topic,msg

      # kafka topic conf goes here
      topic_conf: {}

      # Producer type specific overrides.
      # If you need to configure some producer specific settings,
      # e.g. different batch settings, you can provide them here.
      hasty:
        conf:
          # HastyProducer doesn't block HTTP clients, so we can
          # afford to wait for a largish batch size.
          queue.buffering.max.ms: 1000
          # A custom kafka config. Will call producer.setPollInterval
          # with this value if set.
          producer.poll.interval.ms: 100
      guaranteed:
        conf:
          # GuaranteedProducer does block HTTP clients, so we attempt to send
          # the produce request as soon as possible, rather than waiting
          # for larger batches.
          queue.buffering.max.ms: 0
          # Custom kafka config, will call producer.setPollInterval
          # with this value if set.
          producer.poll.interval.ms: 10

  # This will be rendered in /etc/eventgate/stream-config.yaml
  # and used by EventGate to restrict event schemas to specific streams.
  # test and error streams are automatically configured by this chart.
  # You should add additional stream configs specific to a production releases here.
  # E.g.
  #stream_config:
  #  'mediawiki.api-request':
  #     schema_title: mediawiki/api/request
  # # etc.
