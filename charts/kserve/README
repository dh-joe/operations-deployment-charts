This is a simple Helm chart that wraps the big yaml file that Kserve upstream
provides (basically model-serving only).

The related InferenceService resources are managed by the kserve-inference
chart, this one only takes care of the base KServe setup.

== TLS certificates ==

There is one TLS certificate that is mandatory for this chart, namely the one
used by the Webhook (upgrade/compatibility between api versions, admission, etc..).
The TLS certificate needs to placed into kserve-webhook-server-cert (see secret.yaml),
using the following (default) CN/SANS:
- CN: kserve-webhook-server-service.kserve.svc.cluster.local
- SANs: kserve-webhook-server-service.kserve.svc,
        kserve-webhook-server-service.kserve.svc.cluster,
        kserve-webhook-server-service.kserve.svc.cluster.local
For the moment we create this certificate using the Puppet CA (via cergen).
Please also note that for the moment the target namespace, kserve, needs
to be mentioned in the CN and SANs.

== Inference Services ==

This chart provides the definition of the InferenceService CRD, that allows
the deployment of models and their settings to serve them via Istio/Knative.
The definition of the InferenceService endpoints will be delegated to a separate
chart, kserve-inference, this one will be used only to spin up
the base KServe service and configuration.

== Upgrading ==

The kube-rbac-proxy image is used to add a proxy in front of Prometheus metrics,
usually with something like:
```
- args:
  - --secure-listen-address=0.0.0.0:8443
  - --upstream=http://127.0.0.1:8080/
  - --logtostderr=true
  - --v=10
  image: gcr.io/kubebuilder/kube-rbac-proxy:v0.4.0
  name: kube-rbac-proxy
  ports:
  - containerPort: 8443
    name: https
```
We don't really need it, so it can be safely removed. All the occurrences of port
8443 in the yaml file provided by upstream should be replaced with 8080.

We also don't use cert-manager so the following snippet can be removed as well:
```
apiVersion: cert-manager.io/v1alpha2
kind: Certificate
metadata:
  name: serving-cert
  namespace: kserve-system
spec:
  commonName: kserve-webhook-server-service.kserve.svc
  dnsNames:
  - kserve-webhook-server-service.kserve.svc
  issuerRef:
    kind: Issuer
    name: selfsigned-issuer
  secretName: kserve-webhook-server-cert
---
apiVersion: cert-manager.io/v1alpha2
kind: Issuer
metadata:
  name: selfsigned-issuer
  namespace: kserve
spec:
  selfSigned: {}
```

Together with all annotations like:

```
cert-manager.io/inject-ca-from: kserve/serving-cert
```

The path for the go binary to run for the KServe controller needs to be changed
from /manager to /usr/bin/manager.

With 0.6 a web-app was introduced, but this chart currently doesn't support it.
Clean up all resources with "kserve-models-web-app" accordingly.

Please also add the following snippet to the `env` specs of all containers:
```
{{- if and .Values.kubernetesApi.host .Values.kubernetesApi.port }}
{{- include "wmf.kubernetes.ApiEnv" . | nindent 12 }}
{{- end }}
```
This is needed to avoid TLS certificate validation errors due to the absence of IP SANs.

We also modify the `inferenceservice-config` configmap with:
```
ingress: |-
  {
      "ingressGateway" : "knative-serving/knative-ingress-gateway",
      "ingressService" : "istio-ingressgateway.istio-system.svc.cluster.local",
      "localGateway" : "knative-serving/knative-local-gateway",
      "localGatewayService" : "{{ $.Values.ingress.local_gateway_service }}"
  }
```
We need to set `cluster-local-gateway.istio-system.svc.cluster.local` with Knative
<= 0.18 (from 0.19+ there is no need due to the knative-local-gateway).

The Namespace creation for `kserve` is delegated to helmfile's admin_ng
config, so when importing a new version it needs to be removed. Important: check
the labels defined for the namespace in helmfile vs the ones shipped by upstream,
and correct our settings in case they are different.