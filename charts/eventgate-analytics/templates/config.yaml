{{- define "config.app" -}}
# service-runner EventGate app config.yaml.

# Number of worker processes to spawn.
# Set to 0 to run everything in a single process without clustering.
# Use 'ncpu' to run as many workers as there are CPU units
num_workers: 1

# Log error messages and gracefully restart a worker if v8 reports that it
# uses more heap (note: not RSS) than this many mb.
worker_heap_limit_mb: 200

# Logger info
logging:
  level:  {{ .Values.main_app.log_level }}
  streams:
    - type: stdout
{{- if eq .Values.service.deployment "production" }}
  # Use gelf-stream -> logstash
    - host: logstash.svc.eqiad.wmnet
      port: 12201
      type: gelf
{{- end }}

{{- if .Values.monitoring.enabled }}
# Statsd metrics reporter
metrics:
  name: {{ .Chart.Name }}
  host: localhost
  port: 9125
  type: statsd
{{- end }}

services:
  - name: {{ .Chart.Name }}
    # a relative path or the name of an npm package, if different from name
    module: ./app.js
    conf:
      port: {{ .Values.main_app.port }}

      cors: false

      # more per-service config settings
      user_agent: {{ .Chart.Name }}

      eventgate_factory_module: '/srv/service/lib/factories/wikimedia-eventgate'

      # Mapping of stream names to allowed schemas
      # TODO from web URL in prod?
      stream_config_uri: /etc/eventgate/stream-config.yaml
      # stream_config_uri: https://raw.githubusercontent.com/wikimedia/mediawiki-event-schemas/master/config/stream-config.yaml
      # This field in each event will be used to extract a
      # (possibly relative) schema uri.  The default is $schema.
      # An array of field names will cause EventGate to search for
      # fields by these names in each event, using the first match.
      schema_uri_field: [$schema, meta.schema_uri]

      # If set, this URI will be prepended to any relative schema URI
      # extracted from each event's schema_field.

      # /srv/service/schemas/mediawiki-event-schemas is in the eventgate image cloned at build
      # time from https://gerrit.wikimedia.org/r/mediawiki/event-schemas
      schema_base_uris: [file:///srv/service/schemas/mediawiki-event-schemas/jsonschema/]

      # These schema URIs will be 'precached' on service startup.
      # They should be resolveable by the URI prefixes in schema_base_uris.
      # TODO: we could get this list from a service?
      schema_precache_uris:
        - /error/0.0.3
        - /test/event/0.0.2
        - /test/event/0.0.3
        - /mediawiki/api/request/0.0.1

      # This field in each event will be used to extract a destination 'stream' name.
      # This will equal the destination Kafka topic, unless a topic prefix
      # is also configured.
      stream_field: [meta.stream, meta.topic]

      # Prefix topics with the topic_prefix name and a .
      topic_prefix: {{ .Values.main_app.topic_prefix }}.

      # This field will be used in log messages to uniquely ID each event.
      id_field: meta.id

      # If a validation error is encountered, a validation error event
      # will be produced to this stream.
      error_stream: eventgate.analytics.error.validation

{{- if .Values.main_app.extra_app_conf }}
{{ toYaml .Values.main_app.extra_app_conf | indent 6 }}
{{- end }}

      # kafka configs go here.
      kafka:
        conf:
          metadata.broker.list: {{ .Values.main_app.kafka_broker_list }}
          compression.codec: snappy
          # Match this to what is set on brokers in production.
          message.max.bytes: 4194304
          # Silence noisy connection reaper logging
          # https://github.com/Blizzard/node-rdkafka/issues/326
          # https://github.com/edenhill/librdkafka/issues/768#issuecomment-246302856
          log.connection.close: false
          # Force rdkafka to prefer IPv4 addresses for repeatablity.
          # See also: https://phabricator.wikimedia.org/T218268#5049090
          broker.address.family: v4
{{- if .Values.monitoring.enabled }}
          # Emit rdkafka stats every 30 seconds
          # (Prometheus will only scrape statsd-exporterd every 60 seconds).
          statistics.interval.ms: 30000
{{- end }}
{{- if .Values.main_app.extra_kafka_conf }}
{{ toYaml .Values.main_app.extra_kafka_conf | indent 10 }}
{{- end }}
        # kafka topic conf goes here
        topic_conf: {}

        # Producer type specific overrides.
        # If you need to configure some producer specific settings,
        # e.g. different batch settings, you can provide them here.
        hasty:
          conf:
            # HastyProducer doesn't block HTTP clients, so we can
            # afford to wait for a largish batch size.
            queue.buffering.max.ms: 1000
        guaranteed:
          conf:
            # GuaranteedProducer doese block HTTP clients, so we
            # should use a smaller batch size. Waiting 50 ms
            # will allow for some kafka produce reqeust batching
            # while minimizing latency on the HTTP client.
            queue.buffering.max.ms: 50
{{- end }}
