apiVersion: apps/v1
kind: Deployment
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    {{- include "calico.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.typha.replicaCount }}
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      k8s-app: calico-typha
      {{- include "calico.selectorLabels" . | nindent 6 }}
  strategy:
    rollingUpdate:
      # 100% surge allows a complete up-level set of typha instances to start and become ready,
      # which in turn allows all the back-level typha instances to start shutting down. This
      # means that connections tend to bounce directly from a back-level instance to an up-level
      # instance.
      maxSurge: 100%
      # In case the cluster is unable to schedule extra surge instances, allow at most one instance
      # to shut down to make room. You can set this to 0 if you're sure there'll always be enough room to
      # schedule extra typha instances during an upgrade (because setting it to 0 blocks shutdown until
      # up-level typha instances are online and ready).
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        prometheus.io/scrape: "true"
        prometheus.io/port: "9093"
      labels:
        k8s-app: calico-typha
        {{- include "calico.labels" . | nindent 8 }}
    spec:
      # Since Calico can't network a pod until Typha is up, we need to run Typha itself
      # as a host-networked pod.
      hostNetwork: true
      # Typha supports graceful shut down, disconnecting clients slowly during the grace period.
      # The TYPHA_SHUTDOWNTIMEOUTSECS env var should be kept in sync with this value.
      terminationGracePeriodSeconds: {{ .Values.typha.shutdownTimeoutSeconds }}
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
      {{- with .Values.typha.tolerations }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: calico-node
      priorityClassName: system-cluster-critical
      # fsGroup allows using projected serviceaccount tokens as described here kubernetes/kubernetes#82573
      securityContext:
        fsGroup: 65534
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: calico-typha
          image: "{{ .Values.image.repository }}/{{ .Values.typha.imageName }}:v{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: 5473
              name: calico-typha
              protocol: TCP
          env:
            {{- if .Values.bpf }}
            # Overrides for kubernetes API server host/port. Needed in BPF mode.
            - name: KUBERNETES_SERVICE_HOST
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_host
            - name: KUBERNETES_SERVICE_PORT
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: kubernetes_service_port
            {{- end }}
            # Enable "info" logging by default. Can be set to "debug" to increase verbosity.
            - name: TYPHA_LOGSEVERITYSCREEN
              value: "info"
            # Disable logging to file and syslog since those don't make sense in Kubernetes.
            - name: TYPHA_LOGFILEPATH
              value: "none"
            - name: TYPHA_LOGSEVERITYSYS
              value: "none"
            # Monitor the Kubernetes API to find the number of running instances and rebalance
            # connections.
            - name: TYPHA_CONNECTIONREBALANCINGMODE
              value: "kubernetes"
            - name: TYPHA_DATASTORETYPE
              value: "kubernetes"
            - name: TYPHA_HEALTHENABLED
              value: "true"
            # Since Typha is host-networked, this opens a port on the host.
            - name: TYPHA_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: TYPHA_PROMETHEUSMETRICSPORT
              value: "9093"
            - name: TYPHA_SHUTDOWNTIMEOUTSECS
              value: {{ .Values.typha.shutdownTimeoutSeconds | quote }}
            # Location of the CA bundle Typha uses to authenticate calico/node; volume mount
            #- name: TYPHA_CAFILE
            #  value: /calico-typha-ca/typhaca.crt
            # Common name on the calico/node certificate
            #- name: TYPHA_CLIENTCN
            #  value: calico-node
            # Location of the server certificate for Typha; volume mount
            #- name: TYPHA_SERVERCERTFILE
            #  value: /calico-typha-certs/typha.crt
            # Location of the server certificate key for Typha; volume mount
            #- name: TYPHA_SERVERKEYFILE
            #  value: /calico-typha-certs/typha.key
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9098
              host: localhost
            periodSeconds: 30
            initialDelaySeconds: 30
            timeoutSeconds: 10
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
          readinessProbe:
            httpGet:
              path: /readiness
              port: 9098
              host: localhost
            periodSeconds: 10
            timeoutSeconds: 10
          resources:
            {{- toYaml .Values.typha.resources | nindent 12 }}
      nodeSelector:
        kubernetes.io/os: linux
      {{- with .Values.typha.nodeSelector }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.typha.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: calico-typha
  namespace: kube-system
  labels:
    k8s-app: calico-typha
    {{- include "calico.labels" . | nindent 4 }}
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: calico-typha
      {{- include "calico.selectorLabels" . | nindent 6 }}
